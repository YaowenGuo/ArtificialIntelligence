# 基础

# 应用

# 高级


课程介绍



【10.28-29】深度学习的数据探索与准备

☑ 第1课：NumPy


介绍数组、轴、向量操作、多维数组、如何沿着某个轴应用一个函数；现实世界一些有趣的例子，比如：金融回报计算（Python带循环的方式和NumPy不带循环的方式对比表明NumPy是多么的简单等）。



☑ 第2课：Pandas


介绍Pandas对象、数据索引和选择、Pandas的数据操作、处理缺失数据、合并数据集：Concat和扩展、聚类和分组、时间序列处理、金融应用示例等。



☑ 第3课：Matplotlib


包括基本作图类型：线图、条形图、散点图、做图图像、人生游戏示例，金融的随机漫步模拟、Iris数据集可视化等。

☑ 第4课：缺失值处理与异常值检测


包括删除方法、简单的插补方法、基于模式的方法，了解你的数据，实操案例包括处理缺失数据点，并观察它怎样影响模型性能。异常值检测包括极值分析、接近法、投影法等。

☑ 第5课：数据探索的综合案例


包括建模概述、数据导论、基本的数据清洗、更多的数据探索、特征工程等。

【11.04-05】卷积神经网络Keras实战

☑ 第1课：卷积神经网络基础

介绍感知器、全连接人工神经网络、损失函数、权重乘以输入的矩阵乘法、卷积、框架概述例如AlexNet、训练CIFAR或MNIST数据集、在给定框架下计算参数个数等。


☑ 第2课：Keras基础

介绍模型、层、池化、损失函数、最优化、激活层、Keras技巧包括BatchNormalization、Dropout、正则化等、模型可视化等、用Keras分类CIFAR数据集示例等。



☑ 第3课：迁移学习Keras实战

包括使用预训练模型、添加和删除层、可训练层、调试模型、VGG 16用于CIFAR等。

☑ 第4课：深度学习工具箱

包括数据处理、数据准备、构造模型、拟合模型、测试模型。需要用到本课程所学到的所有技巧。数据包括Kaggle渔业、kaggle分心驾驶、MNIST、CIFAR等。

☑ 第5课：理解卷积神经网络：Keras中的DeepDream

包括用Keras可视化卷积层、DeepDream的Keras实战、构造你自己的DeepDream系统等。

【11.11-12】TensorFlow快速上手

☑ 第1课：TensorFlow基础

介绍用TensorFlow的一个简单线性模型、解释TensorFlow的主要概念包括计算图、变量、常数、最优化、会话对象及使用、保存和加载模型等。


☑ 第2课：卷积神经网络TensorFlow实战

介绍卷积神经网络的理论综述、构造模型等。


☑ 第3课：TensorBoard和调试

包括TensorBoard和调试，全程实例演示。

☑ 第4课：循环神经网络TensorFlow实战

包括循环神经网络的理论基础、以及循环神经网络用于全球污染预测。

☑ 第5课：LSTM和自然语言处理TensorFlow实战

包括LSTM和自然语言处理的理论概述、以及TensorFlow的文本预测、采用中文数据库等。

☑ 第6课：部署TensorFlow模型

包括用TensorFlow Serving部署模型、分布式TensorFlow等。

【11.18-19】PyTorch快速上手

☑ 第1课：PyTorch基础

介绍PyTorch概述、张量表示、梯度下降、反向传播、线性回归、logistic回归等。



☑ 第2课：PyTorch搭建简单的神经网络

以一个简单的神经网络为示例用PyTorch搭建，介绍PyTorch搭建神经网络的基本流程、以及优势及特点等。


☑ 第3课：卷积神经网络PyTorch实战

包括构建卷积神经网络，如果使用GPU、学习率衰减、卷积神经网络的简单介绍和实例等。

☑ 第4课：循环神经网络PyTorch实战

包括循环神经网络和LTSM简单介绍、LSTM在自然语言理解的应用、LSTM在AUTOML方面的应用等等。

☑ 第5课：生成对抗网络Pytorch实战

包括构建生成对抗网络，如果使用GPU、学习率衰减、生成对抗网络的简单介绍和实例等。





Q&A

1.没有基础能不能学？



fastai的口号是让深度学习民主化，希望普通人都能够应用深度学习。我们的课程对零基础非常友好，直接进入环境是短期内迅速提升最有效的办法。



2.不用先学理论再进行实战吗？



我们学开车，最好的办法是上手练习，开多了就熟悉了，而不是先学习车的结构。深度学习也是一样，重在实战和应用。必须的理论，像是开车的规则，我们会在实战中讲解。



3.两天的时间能学的会吗？



我们往期的两天课程很多同学成功调出自己的模型，相信自己！



4.线上的课程和教材也很多，为什么要报这个课？



现存的教材偏重理论，新手难以消化。在实战中会有各种个性化的问题，线下的课程有接受老师面对面交流指导的机会。自己学习是很枯燥，难以坚持的，这里能和一帮志同道合的朋友有更深的接触，一起学习。

本次的深度学习课程主要包括三大部分：
      1） 深度学习核心原理。了解深度学习运行的最核心数学原理，从而对后续的知识点扩展，模型设计，与优化技能打下基础。
      2） 深度学习知识点连接。会涵盖主流的深度学习研究工程应用中碰到的大部分知识点，与大部分学习资料孤立进行知识点介绍不同，会结合主讲人自身总结找到主要知识点之间的联系，便于系统掌握与后续学习。
      3） 介绍不同知识点的代表应用。结合所学的原理以及实例，讲解近期较为重要的图像与语言领域的应用，如增强学习(Reinforcement Learning)，迁移学习(Transfer Learning)，无监督式学习(Unsupervised Learning)下的生成式对抗网络(Generative Adverserial Networks, GANs)，注意力机制模型(Attention Model)等， 方便学员针对自身兴趣的目标进行强化训练提升。
主讲老师：
戎雪健 美国纽约城市大学博士
研究领域包括深度学习，计算机视觉，与图像处理等，尤其是自然场景文字检测与识别方向。在CVPR，ECCV等顶级会议上发表了多篇学术论文，同时他还是CVPR，ICCV，BMVC，WACV等重要视觉会议以及TMM，TIP，CVIU，JVCI等期刊的审稿人。
开课时间：2017年9月9日
学习方式：
在线直播，共10次
每周2次（周六、日晚上20:00-22:00）
直播后提供录制回放视频，在线反复观看，有效期1年
课程大纲

第一课：深度学习的总体介绍
    1. 神经网络：从传统到现代
    2. 深度学习应用特点
    3. 深度学习发展方向
    4. 深度学习流行框架比较 ：用TensorFlow进行课程实例学习与工程部署
    5. 实例：深度学习环境配置，TensorFlow基础／进阶／示例，PyTorch基础

第二课：传统神经网络
    1. 神经网络起源：线性回归
    2. 从线性到非线性：非线性激励
    3. 神经网络的构建：深度广度复杂度扩展
    4. 神经网络的“配件”：损失函数，学习率，动量，过拟合等
    5. 多层感知器
    6. 实例: 线性回归与逻辑回归模型 (TensorFlow, PyTorch)

第三课： 卷积神经网络：基础篇
    1. 链式反向梯度传导
    2. 卷积神经网络－卷积层：正向反向推导
    3. 卷积神经网络－功能层：激活函数，降维，归一化，池化，区域分割
    4. 实例：简单卷积神经网络训练与运行 (TensorFlow, PyTorch)


第四课：卷积神经网络：高级篇
    1. AlexNet：最早的现代神经网络
    2. VGG，GoogleNet，ResNet，DenseNet： 近期的高级卷积网络模型
    3. U-Net：深度图片生成网络
    4. 实例：利用预训练模型进行物体分类／特征提取 (TensorFlow, PyTorch)

第五课：卷积神经网络：目标分类与识别
    1. 目标分类与识别任务介绍
    2. 传统分类识别方法总结
    3. ImageNet与PASCAL VOC数据库
    3. 迁移学习
    4. 个人研究分享：如何设计新的的网络
    5. 实例训练：物体识别／场景识别／文字识别 (TensorFlow)

第六课： 卷积神经网络：目标检测与追踪
    1. 目标检测与追踪任务介绍
    2. 基于手动设计特征的传统目标检测追踪方法总结
    3. 目标检测：RCNN，Fast-RCNN，Faster-RCNN, FPN系列
    4. 目标检测：YOLO，SSD，YOLO9000系列
    5. 目标追踪：Hierarchical Features, Tracking with FCNs系列
    6. TensorFlow官方目标检测接口：Object Detection API
    7. 个人研究分享：自然场景文本检测识别领域的最新方法与动向
    8. 实例：目标检测模型训练／部署 (TensorFlow)

第七课：卷积神经网络：目标分割
    1. 目标分割任务介绍
    2. 传统图片分割方法总结
    3. 全卷积网络
    4. 图像语义分割
    5. 图像实例分割
    6. 目标分割：FCIS, Mask-RCNN系列
    7. 业界应用：目标分类／检测／分割模型在自动驾驶与无人车中的应用
    8. 实例：目标分割模型训练／部署 (TensorFlow)

第八课： 循环神经网络
    1. RNN基本原理
    2. 改进版RNN：门限循环单元
    3. 改进版RNN：长短期记忆单元
    4. 语言特征提取
    5. 编码器 + 解码器结构
    6. 注意力机制模型
    7. 图片标注：学会看图说话
    8. 图片问答：学会看图推理
    9. 业界应用：Language and Vision，语言文字与图像的结合应用
    10. 实例：图片标注与图片问答实例 (TensorFlow, PyTorch)

第九课：无监督式学习
    1. 无监督式学习：以生成式模型为例
    2. 生成式对抗网络：( GANs)
    3. DCGAN：GAN ＋深度学习
    4. Conditional GAN： 生成图片由我控制
    5. InfoGAN： 无监督找特征
    6. Wasserstein GAN： 理论创新
    7. 实例：Pix2Pix/CycleGAN 自定义图片生成 (TensorFlow, PyTorch)

第十课：增强学习
    1. 增强学习基础
    2. DQN 深度增强学习
    3. DQN 改进模型
    4. A3C模型： 高效游戏机器人
    5. ELF模型：简化版《星际争霸》，人工智能游戏测试平台
    6. 实例： DQN用于Atari游戏学习 (TensorFlow)


常见问题：
Q：参加本门课程有什么要求？
A： 本课程不需要任何先修课程，保证了从入门到精通的节奏感。
Q： 课程中需要什么环境？
A： 开发环境以GNU Linux (Ubuntu)为主，深度学习训练与测试需要符合CUDA要求的Nvidia显卡，建议最低 Nvidia Geforce GTX 1060，有条件的尽量 GTX 1080或1080 Ti， 如果有GTX Titan X 更好